{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8826626,
          "sourceType": "datasetVersion",
          "datasetId": 5288601
        }
      ],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Prompt_Test_RAG",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies Installation"
      ],
      "metadata": {
        "id": "RaKs0FbuU7Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qqq transformers accelerate bitsandbytes llama-index-llms-huggingface python-docx"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-07-04T14:11:08.568354Z",
          "iopub.execute_input": "2024-07-04T14:11:08.568824Z",
          "iopub.status.idle": "2024-07-04T14:11:37.917932Z",
          "shell.execute_reply.started": "2024-07-04T14:11:08.568791Z",
          "shell.execute_reply": "2024-07-04T14:11:37.916804Z"
        },
        "trusted": true,
        "id": "-LnRLVarU7Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qqq  docx2txt llama_index.embeddings.huggingface llama-index-readers-file llama_index.llms.huggingface_api llama-index-postprocessor-rankgpt-rerank"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:11:37.920343Z",
          "iopub.execute_input": "2024-07-04T14:11:37.921091Z",
          "iopub.status.idle": "2024-07-04T14:11:56.521567Z",
          "shell.execute_reply.started": "2024-07-04T14:11:37.921047Z",
          "shell.execute_reply": "2024-07-04T14:11:56.520361Z"
        },
        "trusted": true,
        "id": "Iw4dwlZGU7Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Library Imports"
      ],
      "metadata": {
        "id": "MuFc3W-jU7Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import ServiceContext\n",
        "from llama_index.core import set_global_service_context\n",
        "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader,ServiceContext\n",
        "\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:18:43.867796Z",
          "iopub.execute_input": "2024-07-04T14:18:43.868159Z",
          "iopub.status.idle": "2024-07-04T14:18:43.873874Z",
          "shell.execute_reply.started": "2024-07-04T14:18:43.868131Z",
          "shell.execute_reply": "2024-07-04T14:18:43.872697Z"
        },
        "trusted": true,
        "id": "TCmsQdpeU7Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the model in 4-bit space to accomodate hardware requirements - includes compression of weights and a tradeoff in accuracy"
      ],
      "metadata": {
        "id": "2sk7XD60U7Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:12:03.781519Z",
          "iopub.execute_input": "2024-07-04T14:12:03.782355Z",
          "iopub.status.idle": "2024-07-04T14:12:03.788559Z",
          "shell.execute_reply.started": "2024-07-04T14:12:03.782321Z",
          "shell.execute_reply": "2024-07-04T14:12:03.78752Z"
        },
        "trusted": true,
        "id": "31cWO-QzU7Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the LLM Model"
      ],
      "metadata": {
        "id": "H4IJ6qj5U7Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    model_name=\"stabilityai/stablelm-zephyr-3b\",\n",
        "    tokenizer_name=\"stabilityai/stablelm-zephyr-3b\",\n",
        "#     query_wrapper_prompt=PromptTemplate(\"<|system|>\\n<|endoftext|>\\n<|user|>\\n{query_str}<|endoftext|>\\n<|assistant|>\\n\"),\n",
        "#     query_wrapper_prompt = query_wrapper_prompt,\n",
        "    context_window=3900,\n",
        "    max_new_tokens=256,\n",
        "    model_kwargs={\"quantization_config\": quantization_config},\n",
        "    # tokenizer_kwargs={},\n",
        "    generate_kwargs={\"temperature\": 0.8},\n",
        "#     messages_to_prompt=messages_to_prompt,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:16:02.21519Z",
          "iopub.execute_input": "2024-07-04T14:16:02.215584Z",
          "iopub.status.idle": "2024-07-04T14:16:39.231668Z",
          "shell.execute_reply.started": "2024-07-04T14:16:02.215555Z",
          "shell.execute_reply": "2024-07-04T14:16:39.230817Z"
        },
        "trusted": true,
        "id": "yr6wMYaUU7Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Document Ingestion begins.."
      ],
      "metadata": {
        "id": "kQrKea_QU7Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents=SimpleDirectoryReader(\"/kaggle/input/resume23\").load_data()\n",
        "len(documents)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:17:00.531684Z",
          "iopub.execute_input": "2024-07-04T14:17:00.532541Z",
          "iopub.status.idle": "2024-07-04T14:17:01.564812Z",
          "shell.execute_reply.started": "2024-07-04T14:17:00.532506Z",
          "shell.execute_reply": "2024-07-04T14:17:01.563811Z"
        },
        "trusted": true,
        "id": "__wuiKZuU7Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Making LLM and embedding model as global objects.."
      ],
      "metadata": {
        "id": "xwA4rLn7U7Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:17:07.951724Z",
          "iopub.execute_input": "2024-07-04T14:17:07.952043Z",
          "iopub.status.idle": "2024-07-04T14:17:24.957327Z",
          "shell.execute_reply.started": "2024-07-04T14:17:07.95202Z",
          "shell.execute_reply": "2024-07-04T14:17:24.956357Z"
        },
        "trusted": true,
        "id": "u42DBb8YU7Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Storage of documents and their respective embeddings"
      ],
      "metadata": {
        "id": "ZuktfBL2U7Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:19:08.730999Z",
          "iopub.execute_input": "2024-07-04T14:19:08.731352Z",
          "iopub.status.idle": "2024-07-04T14:19:14.92717Z",
          "shell.execute_reply.started": "2024-07-04T14:19:08.731322Z",
          "shell.execute_reply": "2024-07-04T14:19:14.926334Z"
        },
        "trusted": true,
        "id": "1z_kB4_1U7Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:19:19.210555Z",
          "iopub.execute_input": "2024-07-04T14:19:19.21094Z",
          "iopub.status.idle": "2024-07-04T14:19:19.217055Z",
          "shell.execute_reply.started": "2024-07-04T14:19:19.210909Z",
          "shell.execute_reply": "2024-07-04T14:19:19.216136Z"
        },
        "trusted": true,
        "id": "nL9xEaHZU7Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrieval and re-ranking of information after running query against the vector Index, re-ranking is done by the LLM"
      ],
      "metadata": {
        "id": "bm-Vq3ZgU7Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core import QueryBundle\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "\n",
        "from llama_index.postprocessor.rankgpt_rerank import RankGPTRerank\n",
        "\n",
        "\n",
        "def get_retrieved_nodes(\n",
        "    query_str, vector_top_k=5, reranker_top_n=3, with_reranker=False\n",
        "):\n",
        "    query_bundle = QueryBundle(query_str)\n",
        "    # configure retriever\n",
        "    retriever = VectorIndexRetriever(\n",
        "        index=vector_index,\n",
        "        similarity_top_k=vector_top_k,\n",
        "    )\n",
        "    retrieved_nodes = retriever.retrieve(query_bundle)\n",
        "\n",
        "    if with_reranker:\n",
        "        # configure reranker\n",
        "        reranker = RankGPTRerank(\n",
        "            llm=llm,\n",
        "            top_n=reranker_top_n,\n",
        "            verbose=True,\n",
        "        )\n",
        "        retrieved_nodes = reranker.postprocess_nodes(\n",
        "            retrieved_nodes, query_bundle\n",
        "        )\n",
        "\n",
        "    return retrieved_nodes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:19:22.414687Z",
          "iopub.execute_input": "2024-07-04T14:19:22.415296Z",
          "iopub.status.idle": "2024-07-04T14:19:22.422567Z",
          "shell.execute_reply.started": "2024-07-04T14:19:22.415255Z",
          "shell.execute_reply": "2024-07-04T14:19:22.421643Z"
        },
        "trusted": true,
        "id": "sPuDKxwgU7Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"Question:\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:40:12.376508Z",
          "iopub.execute_input": "2024-07-04T14:40:12.37691Z",
          "iopub.status.idle": "2024-07-04T14:40:21.992142Z",
          "shell.execute_reply.started": "2024-07-04T14:40:12.376881Z",
          "shell.execute_reply": "2024-07-04T14:40:21.991381Z"
        },
        "trusted": true,
        "id": "IkcOdeWMU7Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### An example of how information related to query is retrieved"
      ],
      "metadata": {
        "id": "5GUqdlbgU7Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_nodes = get_retrieved_nodes(\n",
        "   query,\n",
        "    vector_top_k=10,\n",
        "    reranker_top_n=3,\n",
        "    with_reranker=True,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:40:31.889406Z",
          "iopub.execute_input": "2024-07-04T14:40:31.889802Z",
          "iopub.status.idle": "2024-07-04T14:40:54.225675Z",
          "shell.execute_reply.started": "2024-07-04T14:40:31.889772Z",
          "shell.execute_reply": "2024-07-04T14:40:54.224679Z"
        },
        "trusted": true,
        "id": "9lalblO8U7Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_retrieved_nodes(nodes) -> None:\n",
        "    result_dicts = []\n",
        "    for node in nodes:\n",
        "        result_dict = {\"Score\": node.score, \"Text\": node.node.get_text()}\n",
        "        result_dicts.append(result_dict)\n",
        "\n",
        "    pretty_print(pd.DataFrame(result_dicts))\n",
        "\n",
        "def pretty_print(df):\n",
        "    return display(HTML(df.to_html().replace(\"\\\\n\", \"<br>\")))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:20:08.071743Z",
          "iopub.execute_input": "2024-07-04T14:20:08.072431Z",
          "iopub.status.idle": "2024-07-04T14:20:08.078746Z",
          "shell.execute_reply.started": "2024-07-04T14:20:08.0724Z",
          "shell.execute_reply": "2024-07-04T14:20:08.077531Z"
        },
        "trusted": true,
        "id": "lUcFYkSrU7Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results of the related information"
      ],
      "metadata": {
        "id": "K5_pGwMwU7Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_retrieved_nodes(new_nodes)"
      ],
      "metadata": {
        "trusted": true,
        "id": "630yRMYiU7Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.response.notebook_utils import display_response\n",
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:20:37.015539Z",
          "iopub.execute_input": "2024-07-04T14:20:37.015909Z",
          "iopub.status.idle": "2024-07-04T14:20:37.027365Z",
          "shell.execute_reply.started": "2024-07-04T14:20:37.015879Z",
          "shell.execute_reply": "2024-07-04T14:20:37.021277Z"
        },
        "trusted": true,
        "id": "7N0VNuZxU7Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Zero-Shot Inference (without using exclusive Prompt template)"
      ],
      "metadata": {
        "id": "Tk3kNwNjU7Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "query_engine = vector_index.as_query_engine(response_mode=\"compact\")\n",
        "\n",
        "start_time = time.time()\n",
        "response = query_engine.query(query)\n",
        "end_time= time.time()\n",
        "display_response(response)\n",
        "\n",
        "print(\"time taken : \",(end_time-start_time))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:41:07.297299Z",
          "iopub.execute_input": "2024-07-04T14:41:07.298178Z",
          "iopub.status.idle": "2024-07-04T14:41:15.714733Z",
          "shell.execute_reply.started": "2024-07-04T14:41:07.298143Z",
          "shell.execute_reply": "2024-07-04T14:41:15.713813Z"
        },
        "trusted": true,
        "id": "5qE2fnUYU7Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define prompt viewing function\n",
        "def display_prompt_dict(prompts_dict):\n",
        "    for k, p in prompts_dict.items():\n",
        "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
        "        display(Markdown(text_md))\n",
        "        print(p.get_template())\n",
        "        display(Markdown(\"<br><br>\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:20:59.961685Z",
          "iopub.execute_input": "2024-07-04T14:20:59.962041Z",
          "iopub.status.idle": "2024-07-04T14:20:59.967566Z",
          "shell.execute_reply.started": "2024-07-04T14:20:59.962012Z",
          "shell.execute_reply": "2024-07-04T14:20:59.966521Z"
        },
        "trusted": true,
        "id": "XjUQtDnsU7Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Displaying default prompt template - one for text processing and the other for making the response in more of brief/compact manner"
      ],
      "metadata": {
        "id": "qZki0lxIU7Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_dict = query_engine.get_prompts()\n",
        "display_prompt_dict(prompts_dict)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:42:05.233821Z",
          "iopub.execute_input": "2024-07-04T14:42:05.234223Z",
          "iopub.status.idle": "2024-07-04T14:42:05.250251Z",
          "shell.execute_reply.started": "2024-07-04T14:42:05.23419Z",
          "shell.execute_reply": "2024-07-04T14:42:05.249297Z"
        },
        "trusted": true,
        "id": "8z_OHX3EU7Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customization of the prompt template"
      ],
      "metadata": {
        "id": "SXSkYhlXU7Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Prompt\n",
        "\n",
        "template = (\"\"\"\n",
        "Context information is below.\n",
        "---------------------\n",
        "{context_str}\n",
        "---------------------\n",
        "Given the context information and not prior knowledge,\n",
        "answer the query asking about candidate resumes and their suitability for specific job roles.\n",
        "Please provide your answer in the form of a structured JSON format containing\n",
        "a list of candidate's resumes along with their qualifications, experience, skills, and relevance to the job role.\n",
        "\n",
        "Query: {query_str}\n",
        "Answer:\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:46:04.955039Z",
          "iopub.execute_input": "2024-07-04T14:46:04.955811Z",
          "iopub.status.idle": "2024-07-04T14:46:04.96048Z",
          "shell.execute_reply.started": "2024-07-04T14:46:04.955778Z",
          "shell.execute_reply": "2024-07-04T14:46:04.959536Z"
        },
        "trusted": true,
        "id": "smDOy3IgU7Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the prompt template compatible with query engine from LlamaIndex"
      ],
      "metadata": {
        "id": "7crEk1TnU7Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_template = Prompt(template)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:46:05.731246Z",
          "iopub.execute_input": "2024-07-04T14:46:05.731798Z",
          "iopub.status.idle": "2024-07-04T14:46:05.735719Z",
          "shell.execute_reply.started": "2024-07-04T14:46:05.731769Z",
          "shell.execute_reply": "2024-07-04T14:46:05.734807Z"
        },
        "trusted": true,
        "id": "yhPnGD6oU7Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### New Query engine with customized prompt template"
      ],
      "metadata": {
        "id": "HDG3HUE0U7Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = vector_index.as_query_engine(response_mode=\"compact\",text_qa_template = qa_template)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:46:06.850724Z",
          "iopub.execute_input": "2024-07-04T14:46:06.851328Z",
          "iopub.status.idle": "2024-07-04T14:46:06.855895Z",
          "shell.execute_reply.started": "2024-07-04T14:46:06.851299Z",
          "shell.execute_reply": "2024-07-04T14:46:06.854954Z"
        },
        "trusted": true,
        "id": "dGYRt8ewU7Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference test"
      ],
      "metadata": {
        "id": "1jxYSSPtU7Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "response = query_engine.query(query)\n",
        "end_time= time.time()\n",
        "display_response(response)\n",
        "\n",
        "print(\"time taken : \",(end_time-start_time))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-04T14:46:14.916171Z",
          "iopub.execute_input": "2024-07-04T14:46:14.917098Z",
          "iopub.status.idle": "2024-07-04T14:46:30.737701Z",
          "shell.execute_reply.started": "2024-07-04T14:46:14.917058Z",
          "shell.execute_reply": "2024-07-04T14:46:30.736783Z"
        },
        "trusted": true,
        "id": "ohhPAhZ_U7Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9VWScsXU7Ty"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}